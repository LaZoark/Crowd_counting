{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "url = 'grafana_data_export.csv'\n",
    "#df1 = pd.read_csv(url)\n",
    "# series = read_csv(url, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "series = read_csv(url,header=1,parse_dates=True)\n",
    "series\n",
    "# print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('grafana_data_export.csv', header=1, engine='python')\n",
    "\n",
    "# 將 'TID(converted)' 欄位轉換為時間戳記，以便進行時間的分組和計算\n",
    "df['TID(converted)'] = pd.to_datetime(df['TID(converted)'], yearfirst=True)\n",
    "\n",
    "# 將 DataFrame 的索引設置為 'TID(converted)' 欄位的時間戳記\n",
    "df.index = df['TID(converted)']\n",
    "\n",
    "# 按照每小時重新取樣，統計每個時間區間內不重複的 MAC 位址數量\n",
    "half_hourly_count = df['MAC'].resample('30T').nunique()\n",
    "\n",
    "series=half_hourly_count\n",
    "print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import lag_plot\n",
    "# series = read_csv(url, header=0, index_col=0)\n",
    "lag_plot(series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import concat\n",
    "# series = read_csv(url, header=0, index_col=0)\n",
    "values = DataFrame(series.values)\n",
    "dataframe = concat([values.shift(1), values], axis=1)\n",
    "dataframe.columns = ['t-1', 't+1']\n",
    "result = dataframe.corr()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import autocorrelation_plot\n",
    "# series = read_csv(url, header=0, index_col=0)\n",
    "autocorrelation_plot(series)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# series = read_csv(url, header=0, index_col=0)\n",
    "plot_acf(series, lags=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "X = series.values\n",
    "# train, test = X[1:len(X)-48], X[len(X)-48:]\n",
    "\n",
    "# train-test split for time series\n",
    "train_size = int(len(series) * 0.8)\n",
    "test_size = len(series) - train_size\n",
    "train, test = series.values[:train_size], series.values[train_size:]\n",
    "\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "# train autoregression\n",
    "# model = AutoReg(train, lags=500)\n",
    "model = AutoReg(train, lags=20)\n",
    "# model = AutoReg(train, lags=3000)\n",
    "model_fit = model.fit()\n",
    "print('Coefficients: %s' % model_fit.params)\n",
    "\n",
    "# make predictions\n",
    "further_pred_length: int = 50\n",
    "predictions = model_fit.predict(start=len(train),\n",
    "                                end=len(train)+len(test)-1+further_pred_length,\n",
    "                                # dynamic=False,\n",
    "                                dynamic=True,\n",
    "                                )\n",
    "# for i in range(len(predictions)):\n",
    "\t# print('predicted=%f, expected = %d' % (predictions[i], test[i]))\n",
    "for i in range(len(test)):\n",
    "  if i % 15 == 0:\n",
    "    print(f'[{i}] predicted={predictions[i]}, expected = {test[i]}')\n",
    "rmse = sqrt(mean_squared_error(test, predictions[:len(test)]))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "fig.suptitle('[AutoRegression] Crowd Forecasting')\n",
    "ax.set_title(f'RMSE={rmse:.2f}, Length of Future prediced: {further_pred_length}')\n",
    "ax.set_xlabel('Time points')\n",
    "ax.set_ylabel('number of people')\n",
    "ax.plot(test, label='GT')\n",
    "ax.plot(predictions, color='red', label='predictions')\n",
    "y_lower, y_upper = ax.get_ybound()\n",
    "ax.vlines(x=len(test), ymin=y_lower, ymax=y_upper, colors='g', linestyles='dashdot')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "connection = mysql.connector.connect(host='localhost',\n",
    "                                     port='3306',\n",
    "                                     user='root',\n",
    "                                     password='yuting89830') \n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#create database\n",
    "#cursor.execute(\"CREATE DATABASE `crowd_fore`;\")\n",
    "\n",
    "#get all name of database\n",
    "# cursor.execute(\"SHOW DATABASES;\")\n",
    "# records = cursor.fetchall()\n",
    "# for r in records:\n",
    "#     print(r)\n",
    "\n",
    "# use database\n",
    "cursor.execute(\"USE `crowd_fore`;\")\n",
    "\n",
    "# create table\n",
    "#cursor.execute(\"CREATE TABLE `forecast`(TID VARCHAR(20) , PD INT , GT INT , RMSE DECIMAL(10,2) , TP INT)\")\n",
    "\n",
    "# # 執行 SQL 查詢\n",
    "# cursor.execute(\"SELECT * FROM forecast;\")  # 假設你的資料表名稱是 forecast\n",
    "\n",
    "# # 取得查詢結果\n",
    "# result = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#清空資料表內容但保留格式\n",
    "#cursor.execute(\"TRUNCATE TABLE `forecast`;\")\n",
    "#修改資料表格式\n",
    "#cursor.execute(\"ALTER TABLE `forecast` MODIFY COLUMN GT INT;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設預測結果從測試集結束後的一個時間點開始，每30分鐘預測一次\n",
    "start_time = series.index[train_size]  # 取得測試集結束後的一個時間點\n",
    "time_interval = pd.Timedelta(minutes=30)  # 時間間隔為30分鐘\n",
    "predicted_time_points = [start_time + i * time_interval for i in range(len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 假設每30分鐘蒐集一次數據\n",
    "sampling_interval = timedelta(minutes=30)\n",
    "\n",
    "# 將TID、預測結果、真實值、RMSE 和 time point 存入資料庫\n",
    "for i in range(len(predictions)):\n",
    "    TID_index = train_size + i  # 在 series 中的索引位置\n",
    "    if TID_index < len(series):\n",
    "        TID = series.index[TID_index]  # 取得對應到的真實時間\n",
    "    else:\n",
    "        # 超出 series 的範圍，每輪增加半小時\n",
    "        last_time = series.index[-1]\n",
    "        TID = last_time + (i - len(series) + train_size) * sampling_interval\n",
    "\n",
    "    PD = float(predictions[i])  # 將 numpy.float64 轉換成 float\n",
    "    GT = float(test[i]) if i < len(test) else None  # 將 numpy.float64 轉換成 float\n",
    "    TP = i  # time point\n",
    "    RMSE = float(sqrt(mean_squared_error(test, predictions[:len(test)])))  # 將 numpy.float64 轉換成 float\n",
    "\n",
    "    print(TID,PD,GT,TP,RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 假設每30分鐘蒐集一次數據\n",
    "sampling_interval = timedelta(minutes=30)\n",
    "\n",
    "# 將TID、預測結果、真實值、RMSE 和 time point 存入資料庫\n",
    "for i in range(len(predictions)):\n",
    "    TID_index = train_size + i  # 在 series 中的索引位置\n",
    "    if TID_index < len(series):\n",
    "        TID = series.index[TID_index]  # 取得對應到的真實時間\n",
    "    else:\n",
    "        # 超出 series 的範圍，每輪增加半小時\n",
    "        last_time = series.index[-1]\n",
    "        TID = last_time + (i - len(series) + train_size) * sampling_interval\n",
    "\n",
    "    PD = float(predictions[i])  # 將 numpy.float64 轉換成 float\n",
    "    GT = float(test[i]) if i < len(test) else None  # 將 numpy.float64 轉換成 float\n",
    "    TP = i  # time point\n",
    "    RMSE = float(sqrt(mean_squared_error(test, predictions[:len(test)])))  # 將 numpy.float64 轉換成 float\n",
    "\n",
    "    print(TID,PD,GT,TP,RMSE)\n",
    "\n",
    "    # 建立插入資料的 SQL 查詢\n",
    "    sql = \"INSERT INTO forecast (TID, PD, GT, RMSE, TP) VALUES (%s, %s, %s, %s, %s);\"\n",
    "    values = (TID, PD, GT, RMSE, TP)\n",
    "\n",
    "    # 執行插入資料\n",
    "    cursor.execute(sql, values)\n",
    "    connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行 SQL 查詢來取得資料表的標題\n",
    "cursor.execute(\"DESCRIBE forecast;\")  # 假設你的資料表名稱是 forecast\n",
    "\n",
    "# 取得查詢結果，即欄位名稱\n",
    "columns = [column[0] for column in cursor.fetchall()]\n",
    "\n",
    "# 印出標題\n",
    "print(\"資料表標題：\")\n",
    "print(columns)\n",
    "\n",
    "# 執行 SQL 查詢來取得資料表內容\n",
    "cursor.execute(\"SELECT * FROM forecast;\")\n",
    "\n",
    "# 取得查詢結果，即資料表內容\n",
    "data = cursor.fetchall()\n",
    "\n",
    "# 印出內容\n",
    "print(\"資料表內容：\")\n",
    "for row in data:\n",
    "    print(row)\n",
    "    \n",
    "#close the database and disconnection with mysql\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
